{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3563e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# optimizer : 학습속도를 빠르고 안정적이게 하는 방법, 오차의 최저점을 찾아가는것\n",
    "#Adam Optimizer에서는 두 개의 momentum을 활용한다. m, v\n",
    "#m : 기존 momentum 방식에서 활용하던대로 Gradient 값을 좀 더 빠르게 계산할 수 있도록 돕는 역활\n",
    "# v : 데이터의 분포가 Sparse한 곳에서 그 영향력을 극대화 시킴으로써 빠르게 sparse한 영역을 벗어날 수 있도록 돕는 역활\n",
    "# m, v를 사용하여 모멘텀 효과와 weight마다 다른 learning rate를 적용하는 adaptive rate효과를 동시에 보는 알고르즘\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "377f8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUp(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_learning_rate, decay_schedule_fn, warmup_steps, power=1.0, name=None):\n",
    "        super().__init__()\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.power = power\n",
    "        self.decay_schedule_fn = decay_schedule_fn\n",
    "        self.name = name\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        with tf.name_scope(self.name or \"WarmUp\") as name:\n",
    "            #neural network의 노드가 많을경우 쉽게 볼수 없기 때문에 단순화 작업이 필요\n",
    "            #구문을 사용해서 레이어 이름별로 범위를 나눠주는 과정\n",
    "            #name scope를 지정하면 계층 구조의 맨 위만 표시\n",
    "            # warm up : 처음에는 reconstruction error만을 이용해 학습하고, 학습이 진행될수록 loss함수에서 KL\n",
    "            #KL-divergence 의 비중을 늘려주는 것\n",
    "            global_step_float = tf.cast(step, tf.float32) #그래프의 훈련횟수(the number of batches)\n",
    "            warmup_step_float = tf.cast(self.warmup_steps, tf.float32) # a few updates with low learning rate before/ at the beginning of training\n",
    "            warmup_percent_done = global_step_float / warmup_steps_float\n",
    "            warmup_learning_rate = self.initial_learning_rate * tf.math.pow(warmup_percent_done, self.power)\n",
    "            return tf.cond(\n",
    "                global_step_float < warmup_steps_float,  \n",
    "                lambda: warmup_learning_rate,\n",
    "                lambda: self.decay_schedule_fn(step),\n",
    "                name=name,\n",
    "            )# (추측)warmup step의 개수는 작은 learning rate를 가질때 발생하는 횟수 이므로 global step보다 클수밖에 없다라고 생각!\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"initial_learning_rate\": self.initial_learning_rate,\n",
    "            \"decay_schedule_fn\": self.decay_schedule_fn,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"power\": self.power,\n",
    "            \"name\": self.name,\n",
    "        }\n",
    "    \n",
    "def create_optimizer(init_lr, num_train_steps, num_warmup_steps):\n",
    "    learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "        initial_learning_rate=init_lr, decay_steps=num_train_steps, end_learning_rate=0.0\n",
    "    )\n",
    "    if num_warmup_steps:\n",
    "        learning_rate_fn = WamUp(\n",
    "        learning_rate=learning_rate_fn,\n",
    "        weight_decay_rate=0.01,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-6,\n",
    "        exclude_from_weight_decay=[\"layer_norm\", \"bias\"],\n",
    "        )\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86909560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamWeightDecay(tf.keras.optimizers.Adam):\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate = 0.001,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-7,\n",
    "        amsgrad=False,\n",
    "        weight_decay_rate=0.0, #0보다 크거나 같은 float 값. 업데이트마다 적용되는 학습률의 감소율\n",
    "        include_in_weight_decay=None,\n",
    "        exclude_from_weight_decay=None,\n",
    "        name=\"AdamWeightDecay\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(learning_rate, bata_1, bata_2, epsilon, amsgrad, name, **kwargs)\n",
    "        self.weight_decay_rate = weight_decay_rate\n",
    "        self._include_in_weight_decay = include_in_weight_decay\n",
    "        self._exclude_from_weight_decay = exclude_from_weight_decay\n",
    "\n",
    "        def from_config(cls, config): #config with WarmUp custom object\n",
    "            custom_objects = {\"WarmUp\": WarmUp}\n",
    "            return super().from_config(config, custom_objects=custom_objects)\n",
    "        \n",
    "        def _prepare_local(self, var_device, var_dtype, apply_state): #var_device, var_dtype : 정확하게 어떻게사용하는지 모르겠음!\n",
    "            super()._prepare_local(var_device, var_dtype, apply_state)\n",
    "            apply_state[\"weight_decay_rate\"] = tf.constant(self.weight_decay_rate, name=\"adam_weight_decay_rate\")\n",
    "            \n",
    "        def _decay_weight_op(self, var, learning_rate, apply_state):\n",
    "            do_decay = self._do_use_weight_decay(var.name)\n",
    "            if do_decay:\n",
    "                return var.assign_sub(\n",
    "                    learning_rate * var * apply_state[\"weight_decay_rate\"], use_locking=self._use_locking\n",
    "                )#사진 참고한거 보면 : gradient descent 구하는 방식으로 추측됨. 원문 코드 보면 next parameter = parameter - learning rate * parameter * weight decay(기울기) 라고 표현\n",
    "            return tf.no_op() #does nothing\n",
    "        \n",
    "\n",
    "        def apply_gradients(self, grads_and_vars, clip_norm, name=None):\n",
    "            grads, tvars = list(zip(*grads_and_vars))\n",
    "            #grads : tf.gradients(loss, tvars) 이므로 loss를 tvars로 미분하는 과정(loss = 기울기 * tvars + 상수항) 그러니까 기울기를 뜻함\n",
    "            #tvars : tf.trainable_variable() 이므로 trainable(bool 형식)이 True일 때 , variable을 학습을 통해 값을 변화시킬것인지\n",
    "            (grads, _) = tf.clip_by_global_norm(grads, clip_norm=clip_norm) # how the model was pre-trained\n",
    "            return super().apply_gradients(zip(grads, tvars))\n",
    "        \n",
    "        def _get_lr(self, var_device, var_dtype, apply_state):\n",
    "            #주어진 state를 가지고 learning rate 검색\n",
    "            if apply_state is None:\n",
    "                return self._decayed_lr_t[var_dtype], {}\n",
    "            \n",
    "            apply_state = apply_state or {}\n",
    "            coefficients = apply_state.get((var_device, var_dtype)) #get(key, value)로 구성되어있으면 key를 통해 value값을 뽑아낸다\n",
    "            if coefficients is None:\n",
    "                coefficients = self._fallback_apply_state(var_device, var_dtype)\n",
    "                apply_state[(var_device, var_dtype)] = coefficients\n",
    "                \n",
    "            return coefficients[\"lr_t\"], dict(apply_state = apply_state)\n",
    "        \n",
    "        def _resource_apply_dense(self, grad, var, apply_state=None):\n",
    "            lr_t, kwargs = self._get_lr(var.device, var.dtype.base_dtype, apply_state)\n",
    "            decay = self._decay_weights_op(var, lr_t, apply_state)\n",
    "            with tf.control_dependencies([decay]): #연산간의 실행 순서를 정해주는 역활\n",
    "                return super()._resource_apply_dense(grad, var, **kwargs)\n",
    "            \n",
    "        def _resource_apply_sparse(self, grad, var, indices, apply_state=None):\n",
    "            lr_t, kwargs = self._get_lr(var.device, var.dtype.base_dtype, apply_state)\n",
    "            decay = self._decay_weights_op(var, lr_t, apply_state)\n",
    "            with tf.control_dependencies([decay]):\n",
    "                return super()._resource_apply_sparse(grad, var, indices, **kwargs)\n",
    "            \n",
    "        def get_config(self):\n",
    "            config = super().get_config()\n",
    "            config.update({\"weight_decay_rate: self.weight_decay_rate\"})\n",
    "            return config\n",
    "        \n",
    "        def _do_use_weight_decay(self, param_name):\n",
    "            if self.weight_decay_rate ==0:\n",
    "                return False\n",
    "            \n",
    "        if self._include_in_weight_decay:\n",
    "            for r in self._include_in_weight_decay:\n",
    "                if re.search(r, param_name) is not None:\n",
    "                    return True\n",
    "\n",
    "        if self._exclude_from_weight_decay:\n",
    "            for r in self._exclude_from_weight_decay:\n",
    "                if re.search(r, param_name) is not None:\n",
    "                    return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a83b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientAccumulator(object):\n",
    "    #SGD를 활용할 경우, gradient에 비해서 오차(Variance)가 존재할 수 있다. 이 때 최적화를 수행할때 발생하는 문제가\n",
    "    # Noisy Gradient Problem이라고 부른다. 이런 문제를 해결하기 위해 두가지 방법을 사용\n",
    "    #1) 모멘텀을 사용하지 않는 옵티마이저를 사용하여 안정적인 학습을 진행했으나, 수렴도가 만족스럽지 않는것\n",
    "    #2) WarmUp을 사용하여 안정적인 학습과 수렴정도도 만족스러웠으나, 하이퍼파라미터에 민감하다는 단점\n",
    "    #그래서 모멘텀을 사용하는 옵티마이저를 활용하면서 하이퍼파라미터에 상대적으로 덜 민감한 방법에 대해 고민한 끝에 Large Batch Size를\n",
    "    # 사용하여 학습이 진행되는 중에 발생하는 Noisy Gradient가 경감되는 것을 확인. \n",
    "    # 단순히 Batch Size를 키우는것도 좋지만, Gpu 의 Memory가 한정적이기때문에 한정된 Gpu Memory내에서 Batch Size를 키우는 효과를 내기위해\n",
    "    # Gradient Accumulation 방법 사용. 위 방법은 Step마다 파라미터를 업데이트 하지 않고, Gradient를 모으다가 일정한 수의 Gradient Vector들이 모이면 파라미터를 업데이트 하는 형식\n",
    "    \"\"\"Distribution strategies-aware gradient accumulation utility.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the accumulator.\"\"\"\n",
    "        self._gradients = []\n",
    "        self._accum_steps = tf.Variable(\n",
    "            initial_value=0, dtype=tf.int64, trainable=False, aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def step(self):\n",
    "        \"\"\"Number of accumulated steps.\"\"\"\n",
    "        return self._accum_steps.value()\n",
    "\n",
    "    @property\n",
    "    def gradients(self):\n",
    "        \"\"\"The accumulated gradients.\"\"\"\n",
    "        return list(\n",
    "            gradient.value() if gradient is not None else gradient for gradient in self._get_replica_gradients()\n",
    "        )\n",
    "\n",
    "    def __call__(self, gradients):\n",
    "        \"\"\"Accumulates :obj:`gradients`.\"\"\"\n",
    "        if not self._gradients:\n",
    "            self._gradients.extend(\n",
    "                [\n",
    "                    tf.Variable(tf.zeros_like(gradient), trainable=False) if gradient is not None else gradient\n",
    "                    for gradient in gradients\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        if len(gradients) != len(self._gradients):\n",
    "            raise ValueError(\"Expected %s gradients, but got %d\" % (len(self._gradients), len(gradients)))\n",
    "\n",
    "        for accum_gradient, gradient in zip(self._get_replica_gradients(), gradients):\n",
    "            if accum_gradient is not None:\n",
    "                accum_gradient.assign_add(gradient)\n",
    "\n",
    "        self._accum_steps.assign_add(1)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the accumulated gradients.\"\"\"\n",
    "        if self._gradients:\n",
    "            self._accum_steps.assign(0)\n",
    "\n",
    "        for gradient in self._get_replica_gradients():\n",
    "            if gradient is not None:\n",
    "                gradient.assign(tf.zeros_like(gradient))\n",
    "\n",
    "    def _get_replica_gradients(self):\n",
    "        if tf.distribute.has_strategy():\n",
    "            # In a replica context, we want to accumulate gradients on each replica\n",
    "            # without synchronization, so we directly assign the value of the\n",
    "            # current replica.\n",
    "            replica_context = tf.distribute.get_replica_context()\n",
    "\n",
    "            if replica_context is None or tf.distribute.get_strategy().num_replicas_in_sync == 1: #replica_context 값이 없거나, gpu 장치 개수가 1개인경우\n",
    "                return self._gradients \n",
    "\n",
    "            return (\n",
    "                gradient.device_map.select_for_current_replica(gradient.values, replica_context)\n",
    "                for gradient in self._gradients\n",
    "            )\n",
    "        else:\n",
    "            return self._gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a28f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
